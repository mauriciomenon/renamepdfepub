#!/usr/bin/env python3
"""
Testes Abrangentes do Sistema v0.11.0
====================================

Suite completa de testes para validar todas as funcionalidades
dos algoritmos, interface web e sistema de relat√≥rios.
"""

import unittest
import json
import tempfile
import os
import sys
from pathlib import Path
from unittest.mock import patch, MagicMock
import time

# Adiciona o diret√≥rio raiz ao path
sys.path.insert(0, str(Path(__file__).parent))

try:
    from advanced_algorithm_comparison import (
        AlgorithmComparison, BasicParser, EnhancedParser, 
        SmartInferencer, HybridOrchestrator, BrazilianSpecialist
    )
    from simple_report_generator import SimpleReportGenerator
    from demo_system import create_demo_data, generate_html_report
except ImportError as e:
    print(f"‚ö† Erro de importa√ß√£o: {e}")
    print("Executando testes b√°sicos...")

class TestAlgorithmSystem(unittest.TestCase):
    """Testes para o sistema de algoritmos"""
    
    def setUp(self):
        """Configura√ß√£o inicial dos testes"""
        self.test_files = [
            "Python_para_Desenvolvedores_Casa_do_Codigo.pdf",
            "JavaScript_Moderno_OReilly.epub", 
            "Machine_Learning_Novatec_Jo√£o_Silva.pdf",
            "React_Native_Desenvolvimento_Maria_Santos.epub",
            "Data_Science_Python_Packt.pdf"
        ]
        
    def test_basic_parser_exists(self):
        """Testa se BasicParser existe e √© instanci√°vel"""
        try:
            parser = BasicParser()
            self.assertIsNotNone(parser)
            self.assertTrue(hasattr(parser, 'extract_metadata'))
        except NameError:
            self.skipTest("BasicParser n√£o encontrado")
    
    def test_enhanced_parser_exists(self):
        """Testa se EnhancedParser existe e √© instanci√°vel"""
        try:
            parser = EnhancedParser()
            self.assertIsNotNone(parser)
            self.assertTrue(hasattr(parser, 'extract_metadata'))
        except NameError:
            self.skipTest("EnhancedParser n√£o encontrado")
    
    def test_smart_inferencer_exists(self):
        """Testa se SmartInferencer existe e √© instanci√°vel"""
        try:
            inferencer = SmartInferencer()
            self.assertIsNotNone(inferencer)
            self.assertTrue(hasattr(inferencer, 'extract_metadata'))
        except NameError:
            self.skipTest("SmartInferencer n√£o encontrado")
    
    def test_hybrid_orchestrator_exists(self):
        """Testa se HybridOrchestrator existe e √© instanci√°vel"""
        try:
            orchestrator = HybridOrchestrator()
            self.assertIsNotNone(orchestrator)
            self.assertTrue(hasattr(orchestrator, 'extract_metadata'))
        except NameError:
            self.skipTest("HybridOrchestrator n√£o encontrado")
    
    def test_brazilian_specialist_exists(self):
        """Testa se BrazilianSpecialist existe e √© instanci√°vel"""
        try:
            specialist = BrazilianSpecialist()
            self.assertIsNotNone(specialist)
            self.assertTrue(hasattr(specialist, 'extract_metadata'))
            self.assertTrue(hasattr(specialist, 'is_brazilian_publisher'))
        except NameError:
            self.skipTest("BrazilianSpecialist n√£o encontrado")

class TestBrazilianSpecialist(unittest.TestCase):
    """Testes espec√≠ficos para o Brazilian Specialist"""
    
    def setUp(self):
        """Configura√ß√£o inicial"""
        try:
            self.specialist = BrazilianSpecialist()
        except NameError:
            self.skipTest("BrazilianSpecialist n√£o dispon√≠vel")
    
    def test_brazilian_publisher_detection(self):
        """Testa detec√ß√£o de editoras brasileiras"""
        test_cases = [
            ("Casa do C√≥digo", True),
            ("Novatec", True),
            ("√ârica", True),
            ("Brasport", True),
            ("Alta Books", True),
            ("O'Reilly", False),
            ("Packt", False),
            ("Manning", False)
        ]
        
        for publisher, expected in test_cases:
            with self.subTest(publisher=publisher):
                result = self.specialist.is_brazilian_publisher(publisher)
                self.assertEqual(result, expected, 
                    f"Falha na detec√ß√£o: {publisher} deveria ser {expected}")
    
    def test_brazilian_name_patterns(self):
        """Testa detec√ß√£o de padr√µes de nomes brasileiros"""
        test_names = [
            ("Jo√£o Silva", True),
            ("Maria Santos", True),
            ("Ana Costa", True),
            ("Carlos Oliveira", True),
            ("John Smith", False),
            ("Jane Doe", False)
        ]
        
        for name, expected in test_names:
            with self.subTest(name=name):
                result = self.specialist.has_brazilian_name_pattern(name)
                self.assertEqual(result, expected,
                    f"Padr√£o de nome: {name} deveria ser {expected}")
    
    def test_portuguese_language_detection(self):
        """Testa detec√ß√£o de palavras em portugu√™s"""
        test_texts = [
            ("programa√ß√£o python", True),
            ("desenvolvimento web", True),
            ("tecnologia da informa√ß√£o", True),
            ("programming python", False),
            ("web development", False)
        ]
        
        for text, expected in test_texts:
            with self.subTest(text=text):
                result = self.specialist.has_portuguese_words(text)
                self.assertEqual(result, expected,
                    f"Detec√ß√£o de portugu√™s: {text} deveria ser {expected}")

class TestAlgorithmComparison(unittest.TestCase):
    """Testes para o sistema de compara√ß√£o de algoritmos"""
    
    def setUp(self):
        """Configura√ß√£o inicial"""
        try:
            self.comparison = AlgorithmComparison()
        except NameError:
            self.skipTest("AlgorithmComparison n√£o dispon√≠vel")
    
    def test_algorithm_initialization(self):
        """Testa se todos os algoritmos s√£o inicializados"""
        self.assertIsNotNone(self.comparison.algorithms)
        self.assertGreaterEqual(len(self.comparison.algorithms), 5)
        
        expected_algorithms = [
            'Basic Parser', 'Enhanced Parser', 'Smart Inferencer',
            'Hybrid Orchestrator', 'Brazilian Specialist'
        ]
        
        for alg_name in expected_algorithms:
            self.assertIn(alg_name, self.comparison.algorithms,
                f"Algoritmo {alg_name} n√£o encontrado")
    
    def test_metadata_extraction(self):
        """Testa extra√ß√£o b√°sica de metadados"""
        test_filename = "Python_Cookbook_David_Beazley_OReilly_2013.pdf"
        
        try:
            results = self.comparison.test_single_file(test_filename)
            self.assertIsInstance(results, dict)
            self.assertIn('filename', results)
            self.assertIn('results', results)
        except Exception as e:
            self.skipTest(f"Teste de extra√ß√£o falhou: {e}")

class TestReportGeneration(unittest.TestCase):
    """Testes para gera√ß√£o de relat√≥rios"""
    
    def test_demo_data_creation(self):
        """Testa cria√ß√£o de dados de demonstra√ß√£o"""
        try:
            data = create_demo_data()
            self.assertIsInstance(data, dict)
            self.assertIn('test_info', data)
            self.assertIn('algorithm_summary', data)
            self.assertIn('detailed_results', data)
        except NameError:
            self.skipTest("create_demo_data n√£o dispon√≠vel")
    
    def test_html_report_generation(self):
        """Testa gera√ß√£o de relat√≥rio HTML"""
        try:
            data = create_demo_data()
            html_content = generate_html_report(data)
            
            self.assertIsInstance(html_content, str)
            self.assertIn('<html', html_content.lower())
            self.assertIn('renamepdfepub', html_content.lower())
            self.assertIn('algoritmos', html_content.lower())
        except NameError:
            self.skipTest("generate_html_report n√£o dispon√≠vel")
    
    def test_simple_report_generator(self):
        """Testa SimpleReportGenerator"""
        try:
            generator = SimpleReportGenerator()
            self.assertIsNotNone(generator)
            self.assertTrue(hasattr(generator, 'generate_html_report'))
        except NameError:
            self.skipTest("SimpleReportGenerator n√£o dispon√≠vel")

class TestFileStructure(unittest.TestCase):
    """Testes para estrutura de arquivos"""
    
    def test_required_files_exist(self):
        """Testa se arquivos obrigat√≥rios existem"""
        required_files = [
            'advanced_algorithm_comparison.py',
            'simple_report_generator.py',
            'streamlit_interface.py',
            'web_launcher.py',
            'demo_system.py'
        ]
        
        for filename in required_files:
            file_path = Path(filename)
            self.assertTrue(file_path.exists(), 
                f"Arquivo obrigat√≥rio n√£o encontrado: {filename}")
    
    def test_python_syntax(self):
        """Testa sintaxe Python dos arquivos principais"""
        python_files = [
            'advanced_algorithm_comparison.py',
            'simple_report_generator.py',
            'web_launcher.py',
            'demo_system.py'
        ]
        
        for filename in python_files:
            if Path(filename).exists():
                with self.subTest(filename=filename):
                    try:
                        with open(filename, 'r', encoding='utf-8') as f:
                            compile(f.read(), filename, 'exec')
                    except SyntaxError as e:
                        self.fail(f"Erro de sintaxe em {filename}: {e}")

class TestPerformance(unittest.TestCase):
    """Testes de performance"""
    
    def test_algorithm_execution_time(self):
        """Testa tempo de execu√ß√£o dos algoritmos"""
        try:
            comparison = AlgorithmComparison()
            test_filename = "Test_Book_Example.pdf"
            
            start_time = time.time()
            results = comparison.test_single_file(test_filename)
            execution_time = time.time() - start_time
            
            # Deve executar em menos de 5 segundos
            self.assertLess(execution_time, 5.0,
                f"Execu√ß√£o muito lenta: {execution_time:.2f}s")
            
        except NameError:
            self.skipTest("AlgorithmComparison n√£o dispon√≠vel")
    
    def test_memory_usage(self):
        """Testa uso b√°sico de mem√≥ria"""
        # Teste simples de cria√ß√£o de objetos
        try:
            objects = []
            for _ in range(100):
                comparison = AlgorithmComparison()
                objects.append(comparison)
            
            # Se chegou at√© aqui, n√£o h√° vazamento √≥bvio
            self.assertEqual(len(objects), 100)
            
        except MemoryError:
            self.fail("Poss√≠vel vazamento de mem√≥ria detectado")
        except NameError:
            self.skipTest("AlgorithmComparison n√£o dispon√≠vel")

class TestIntegration(unittest.TestCase):
    """Testes de integra√ß√£o"""
    
    def test_end_to_end_workflow(self):
        """Testa fluxo completo end-to-end"""
        try:
            # 1. Cria comparador
            comparison = AlgorithmComparison()
            
            # 2. Executa teste
            test_file = "Integration_Test_Book.pdf"
            results = comparison.test_single_file(test_file)
            
            # 3. Verifica estrutura do resultado
            self.assertIn('filename', results)
            self.assertIn('results', results)
            
            # 4. Gera relat√≥rio
            generator = SimpleReportGenerator()
            report_data = {
                'test_info': {'total_books': 1},
                'algorithm_summary': {},
                'detailed_results': [results]
            }
            
            html_report = generator.generate_html_report(report_data)
            self.assertIsInstance(html_report, str)
            self.assertGreater(len(html_report), 1000)  # Relat√≥rio substancial
            
        except NameError as e:
            self.skipTest(f"Componentes n√£o dispon√≠veis: {e}")

def run_comprehensive_tests():
    """Executa todos os testes de forma organizada"""
    print("üß™ EXECUTANDO TESTES ABRANGENTES v0.11.0")
    print("=" * 60)
    
    # Configura√ß√µes do unittest
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # Adiciona todas as classes de teste
    test_classes = [
        TestAlgorithmSystem,
        TestBrazilianSpecialist, 
        TestAlgorithmComparison,
        TestReportGeneration,
        TestFileStructure,
        TestPerformance,
        TestIntegration
    ]
    
    for test_class in test_classes:
        tests = loader.loadTestsFromTestCase(test_class)
        suite.addTests(tests)
    
    # Executa testes
    runner = unittest.TextTestRunner(
        verbosity=2,
        failfast=False,
        stream=sys.stdout
    )
    
    print(f"\n Iniciando {suite.countTestCases()} testes...")
    result = runner.run(suite)
    
    # Relat√≥rio final
    print("\n" + "=" * 60)
    print("üìä RELAT√ìRIO FINAL DOS TESTES")
    print("=" * 60)
    
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    skipped = len(result.skipped) if hasattr(result, 'skipped') else 0
    success = total_tests - failures - errors - skipped
    
    print(f" Sucessos: {success}")
    print(f" Falhas: {failures}")
    print(f"üî• Erros: {errors}")
    print(f"‚è≠ Pulados: {skipped}")
    print(f"üìà Taxa de Sucesso: {(success/total_tests)*100:.1f}%")
    
    if failures > 0:
        print(f"\nüîç FALHAS DETECTADAS:")
        for test, traceback in result.failures:
            print(f"  ‚Ä¢ {test}: {traceback.splitlines()[-1]}")
    
    if errors > 0:
        print(f"\nüí• ERROS DETECTADOS:")
        for test, traceback in result.errors:
            print(f"  ‚Ä¢ {test}: {traceback.splitlines()[-1]}")
    
    success_rate = (success/total_tests)*100
    if success_rate >= 80:
        print(f"\nüéâ TESTES APROVADOS! ({success_rate:.1f}% de sucesso)")
        return True
    else:
        print(f"\n‚ö† ATEN√á√ÉO: Taxa de sucesso baixa ({success_rate:.1f}%)")
        return False

def main():
    """Fun√ß√£o principal"""
    print("üî¨ SISTEMA DE TESTES RENAMEPDFEPUB v0.11.0")
    print("Validando todas as funcionalidades implementadas...")
    
    success = run_comprehensive_tests()
    
    if success:
        print("\n Todos os testes principais passaram!")
        print(" Sistema pronto para release!")
    else:
        print("\n‚ö† Alguns testes falharam.")
        print("üîß Verifique os logs acima para detalhes.")
    
    return 0 if success else 1

if __name__ == "__main__":
    exit(main())